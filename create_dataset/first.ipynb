{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c0d3f7-4564-4c30-86e5-e8aad73260d8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Using cached pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-24.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecc09dd7-4741-41e2-80f2-cf435874494d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2022.7.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
      "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.2.0 (from torch)\n",
      "  Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.2.1-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n",
      "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
      "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Using cached triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
      "Using cached torchvision-0.17.1-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n",
      "Using cached torchaudio-2.2.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
      "Using cached nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 torch-2.2.1 torchaudio-2.2.1 torchvision-0.17.1 triton-2.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d5162ff-14d5-43c4-b3fe-7387b1b9b23b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Using cached accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from accelerate) (6.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.2.1)\n",
      "Collecting huggingface-hub (from accelerate)\n",
      "  Using cached huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting safetensors>=0.3.1 (from accelerate)\n",
      "  Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2022.7.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Collecting fsspec (from torch>=1.10.0->accelerate)\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.64.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Using cached accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
      "Using cached safetensors-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, accelerate\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2022.7.1\n",
      "    Uninstalling fsspec-2022.7.1:\n",
      "      Successfully uninstalled fsspec-2022.7.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.27.2 fsspec-2024.2.0 huggingface-hub-0.21.3 safetensors-0.4.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple/\n",
      "Collecting bitsandbytes\n",
      "  Using cached bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->bitsandbytes) (1.26.2)\n",
      "Using cached bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.42.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install accelerate\n",
    "! pip install -i https://pypi.org/simple/ bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "678b8247-cee4-4e5b-ad22-d75f8ce427b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvideoreader\n",
      "  Using cached pyvideoreader-0.5.6-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opencv-python (from pyvideoreader)\n",
      "  Using cached opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python->pyvideoreader) (1.26.2)\n",
      "Using cached pyvideoreader-0.5.6-py3-none-any.whl (7.2 kB)\n",
      "Using cached opencv_python-4.9.0.80-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.2 MB)\n",
      "Installing collected packages: opencv-python, pyvideoreader\n",
      "Successfully installed opencv-python-4.9.0.80 pyvideoreader-0.5.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install pyvideoreader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b6efd49-2ea4-4553-a0d1-cd7c8bc050ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c4fd2e6-3518-4b0c-af58-e952ca68a7bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a0d30e-2ed9-4e1e-b54a-adaebd94ecf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ff436f7-44bf-4843-8bea-445bc2ce58fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8e74e49-2d4f-406f-8a8e-a2283828f04d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__CUDNN VERSION: 8902\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: NVIDIA A10G\n",
      "__CUDA Device Total Memory [GB]: 23.609475072\n"
     ]
    }
   ],
   "source": [
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21472716-6be5-472f-ace1-99356d539a36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.33.9)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\n",
      "Requirement already satisfied: botocore<1.34.0,>=1.33.9 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.33.9)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.9.0,>=0.8.2 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.34.0,>=1.33.9->boto3) (2.8.2)\n",
      "Collecting urllib3<2.1,>=1.25.4 (from botocore<1.34.0,>=1.33.9->boto3)\n",
      "  Using cached urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.0,>=1.33.9->boto3) (1.16.0)\n",
      "Using cached urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "Installing collected packages: urllib3\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.1.0\n",
      "    Uninstalling urllib3-2.1.0:\n",
      "      Successfully uninstalled urllib3-2.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "distributed 2022.7.0 requires tornado<6.2,>=6.0.3, but you have tornado 6.4 which is incompatible.\n",
      "sagemaker 2.199.0 requires urllib3<1.27, but you have urllib3 2.0.7 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed urllib3-2.0.7\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install boto3 Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3844b3e8-9d12-4444-97d7-d5343cef6669",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "Successfully installed tokenizers-0.15.2 transformers-4.38.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81e6061d-378c-4414-a5c4-8d3af9ae0f6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting decord\n",
      "  Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl.metadata (422 bytes)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from decord) (1.26.2)\n",
      "Using cached decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
      "Installing collected packages: decord\n",
      "Successfully installed decord-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install decord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11d66211-8485-42ed-8721-60b434408245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (10.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1528303-b775-4da3-a7c5-2bef43b1d170",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.10/site-packages (1.13.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.10.13)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b3428-1b4f-4a65-806a-18f2c8a37387",
   "metadata": {},
   "source": [
    "# Get data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bb986936-4fa4-4f13-914c-446afde45c4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "s3 = boto3.client('s3', region_name='me-central-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a64a9df2-305c-47ac-b310-fc92ccf0e14f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [06:33<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_dataset_using_boto3(bucket, prefix):     \n",
    "    s3_client = boto3.client(\"s3\", region_name=\"me-central-1\")   \n",
    "    \n",
    "    \n",
    "    # Use the list_objects function to get a list of objects     \n",
    "    objects = s3_client.list_objects(Bucket=bucket, Prefix=prefix)      \n",
    "    for obj in tqdm(objects['Contents']):    \n",
    "        key = obj['Key']\n",
    "        if key.endswith('/'):             \n",
    "            local_dir = os.path.join('./tmp', key)\n",
    "            if not os.path.exists(local_dir):                       \n",
    "                os.makedirs(local_dir) \n",
    "                \n",
    "        else:             \n",
    "            #print('key.name', key)  \n",
    "            local_file_path = os.path.join('./tmp', key)\n",
    "            os.makedirs(os.path.dirname(local_file_path), exist_ok=True)\n",
    "            #s3_client.download_file(bucket, obj['Key'], './'+obj['Key'])             \n",
    "            with open(local_file_path, 'wb') as data:                 \n",
    "                s3_client.download_fileobj(bucket, key, data)\n",
    "                \n",
    "                \n",
    "#bucket = 'mbz-hpc-aws-master'     \n",
    "#prefix = 'AROARU6TOWKRU3FNVE2PB:Thanh.Ho@mbzuai.ac.ae/HACER/'     \n",
    "#get_dataset_using_boto3(bucket, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad61d1df-4f86-4ec8-9303-733e2e101efb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('tmp/HACER'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e0127-8217-41b2-b50a-40b2e53a13ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c5a25-b6db-440f-b8a3-d878cd1fe0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc24f436-eeb4-43af-9bdc-d86e272c833b",
   "metadata": {},
   "source": [
    "# Extract activity and emotion from raw output of LLaVA and Video-ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "766719ff-96b6-4e66-8b6f-54ca216e294e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74fd580e45547949e22cbc4978b1f34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64ff55e6f5484313bcefb02c15e0280d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "access_token = \"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\"\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else \"cpu\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model_name = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=access_token)\n",
    "#tokenizer.pad_token_id = tokenizer.eos_token_id    \n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    token=access_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9c97d3dc-9c58-437a-ade3-7be3a4963705",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>standup_happy_23_t</td>\n",
       "      <td>The woman in the video is wearing a red dress ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sitdown_angry_7_h</td>\n",
       "      <td>The woman in the video is sitting down and hol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>standup_happy_9_h</td>\n",
       "      <td>The woman in the video is wearing a black and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink_sad_6_m</td>\n",
       "      <td>The man is sitting on a chair and smoking a ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>putonglasses_neutral_11_m</td>\n",
       "      <td>The man is sitting on a chair and smoking a ci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Video Name  \\\n",
       "0         standup_happy_23_t   \n",
       "1          sitdown_angry_7_h   \n",
       "2          standup_happy_9_h   \n",
       "3              drink_sad_6_m   \n",
       "4  putonglasses_neutral_11_m   \n",
       "\n",
       "                                              Output  \n",
       "0  The woman in the video is wearing a red dress ...  \n",
       "1  The woman in the video is sitting down and hol...  \n",
       "2  The woman in the video is wearing a black and ...  \n",
       "3  The man is sitting on a chair and smoking a ci...  \n",
       "4  The man is sitting on a chair and smoking a ci...  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('smartcare_eval_output_videochatgpt_1.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "a27ff93e-8dce-47ff-8bf5-25dc91446cda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.iloc[281]['Output'] = 'In the video, a woman is sitting on a chair and putting on glasses. The woman is also seen taking off her glasses and putting on a jacket. The woman is wearing a black robe and a veil.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "262b9661-1137-43ff-b91c-c26103dd5eda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5e5d039b-9703-4915-9f59-d674e5a98908",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "- Activity: sitting, putting on glasses, taking off glasses, putting on jacket - Emotion: unidentified\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "text = 'In the video, a woman is sitting on a chair and putting on glasses. The woman is also seen taking off her glasses and putting on a jacket. The woman is wearing a black robe and a veil.'\n",
    "\n",
    "def extract_act_emo_classes(text, model, tokenizer):\n",
    "    inputs = [\n",
    "        \" <s>[INST] <<SYS>>\"\n",
    "        \"You are a virtual assistant. Your task is to help me extract activity and emotion classes from the input text. \" \n",
    "        \"There are 9 activity classes: drink, put on glasses, put on jacket, read, sit down, stand up, take off glasses, take off jacket, and write. \" \n",
    "        \"There are also 5 emotion classes: happy, neutral, sad, angry, and disgust. Please analyze the input text and try to identify these classes if they are present. \"\n",
    "        \"If no emotion class is mentioned in the input, the output for emotion should be 'unidentified'. Please refer to the given samples to better understand your task. \"\n",
    "        \"<</SYS>>\"\n",
    "        \"Input: The woman in the video is sitting down and wearing a red dress. She is also wearing a veil and a gold necklace. The woman appears to be happy and content.[/INST]\"\n",
    "        \"Output: - Activity: sitting down - Emotion: happy, content </s>\"\n",
    "        \"<s>[INST] Input: In the video, a woman is standing in a room and talking to a man. The woman is wearing a black and white dress and a headscarf. The man is wearing a suit and tie. The woman is smiling and the man is looking at her. The activity is a conversation between the two individuals, and the emotion displayed is happiness.[/INST]\"\n",
    "        \"Output: - Activity: standing, talking, smiling - Emotion: happy </s>\"\n",
    "        \"<s>[INST] Input: The woman in the video is standing in a room, wearing a black and white dress and a black veil. She is holding a cup in her hand. The video shows her walking around the room and sitting down. The emotion displayed by the woman is happiness.[/INST]\"\n",
    "        \"Output: - Activity: standing, holding a cup, sitting down - Emotion: happy </s>\"\n",
    "        \"<s>[INST] Input: The man in the video is smoking a cigarette and drinking a glass of water. He is also seen taking off his glasses and putting them back on. The emotion displayed in the video is neutral.[/INST]\"\n",
    "        \"Output: - Activity: smoking, drinking, taking off his glasses - Emotion: neutral </s>\"\n",
    "        \"<s>[INST] Input: The woman in the video is reading a book while sitting on a chair.[/INST]\"\n",
    "        \"Output: - Activity: reading, sitting - Emotion: unidentified </s>\"\n",
    "        f\"<s>[INST] Input: {text}\"\n",
    "        \"Output: \"\n",
    "    ]\n",
    "    model_inputs = tokenizer(inputs, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(**model_inputs, \n",
    "                                   temperature=0.1,  # Adjust the temperature as needed\n",
    "                                   max_length=model_inputs[\"input_ids\"].shape[1] + 50,  # Set the maximum number of new tokens\n",
    "                                   eos_token_id=tokenizer.eos_token_id  \n",
    "                                  )\n",
    "    input_length = model_inputs[\"input_ids\"].shape[1]\n",
    "    output_length = generated_ids.shape[1]\n",
    "\n",
    "    # Extract only the new tokens from the generated output\n",
    "    new_tokens_ids = generated_ids[:, input_length:output_length]\n",
    "\n",
    "    # Decode the new tokens\n",
    "    new_tokens = tokenizer.batch_decode(new_tokens_ids, skip_special_tokens=True)\n",
    "\n",
    "    return new_tokens[0]\n",
    "\n",
    "a = extract_act_emo_classes(text, model, tokenizer)\n",
    "print(a)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "fc57aee9-9e03-4915-bc36-ab9fe47e4ecc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [08:03<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "extracted_output_ls = []\n",
    "for i in tqdm(range(len(df))):\n",
    "    text = df.iloc[i]['Output']\n",
    "    extracted_output = extract_act_emo_classes(text, model, tokenizer)\n",
    "    extracted_output_ls.append(extracted_output)\n",
    "    \n",
    "df['Extracted_Output'] = extracted_output_ls\n",
    "df.to_csv('smartcare_eval_output_videochatgpt_1_extracted.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753ecc2f-00eb-4733-9a91-0abbc39cc272",
   "metadata": {},
   "source": [
    "# Extract mid frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81b1f213-1a15-4925-b5e1-cb666f869ace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sitdown_angry_12_h.mp4',\n",
       " 'putonglasses_angry_8_s.mp4',\n",
       " 'sitdown_neutral_15_k.mp4',\n",
       " 'sitdown_sad_8_l.mp4',\n",
       " 'takeoffglasses_angry_7_j.mp4']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "videos_folder = 'tmp/HACER_video'\n",
    "ls_videos = os.listdir(videos_folder)\n",
    "ls_videos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "913e3a5e-5658-4dc5-8770-9f690f308573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:32<00:00, 14.90it/s]\n"
     ]
    }
   ],
   "source": [
    "num_frame_arr = []\n",
    "for video_name in tqdm(ls_videos):\n",
    "    video_path = os.path.join(videos_folder , video_name)\n",
    "    vr = VideoReader(video_path)\n",
    "    total_frame_num = len(vr)\n",
    "    num_frame_arr.append(total_frame_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "82b01648-8652-40f1-9075-99e4a46597d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max number of frames:  648\n",
      "Min number of frames:  30\n",
      "Mean number of frames:  165.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_frame_arr_np = np.array(num_frame_arr)\n",
    "print(\"Max number of frames: \", np.max(num_frame_arr_np))\n",
    "print(\"Min number of frames: \", np.min(num_frame_arr_np))\n",
    "print(\"Mean number of frames: \", np.round(np.mean(num_frame_arr_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d042a177-1717-4849-b3b7-9514e954bb7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from decord import VideoReader\n",
    "from decord import cpu, gpu\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dcdb2a48-75e9-464d-9416-590166acdef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_frames_video(vis_path):\n",
    "    \"\"\"\n",
    "    Load video frames from a video file.\n",
    "\n",
    "    Parameters:\n",
    "    vis_path (str): Path to the video file.\n",
    "    n_clips (int): Number of clips to extract from the video. Defaults to 1.\n",
    "    num_frm (int): Number of frames to extract from each clip. Defaults to 100.\n",
    "\n",
    "    Returns:\n",
    "    list: List of PIL.Image.Image objects representing video frames.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load video with VideoReader\n",
    "    vr = VideoReader(vis_path)\n",
    "    total_frame_num = len(vr)\n",
    "\n",
    "    # Get indices of frames to extract\n",
    "    mid_idx = total_frame_num//2 - 1\n",
    "    img_array = vr[mid_idx].asnumpy()\n",
    "    img = Image.fromarray(img_array)\n",
    "    \n",
    "    # frame_idx = [mid_idx]\n",
    "    # Extract frames as numpy array\n",
    "    #img_array = vr.get_batch(frame_idx).asnumpy()\n",
    "    \n",
    "    # Set target image height and width\n",
    "    #target_h, target_w = 224, 224\n",
    "    # If image shape is not as target, resize it\n",
    "    #if img_array.shape[-3] != target_h or img_array.shape[-2] != target_w:\n",
    "    #    img_array = torch.from_numpy(img_array).permute(0, 3, 1, 2).float()\n",
    "    #    img_array = torch.nn.functional.interpolate(img_array, size=(target_h, target_w))\n",
    "    #    img_array = img_array.permute(0, 2, 3, 1).to(torch.uint8).numpy()\n",
    "    # Reshape array to match number of clips and frames\n",
    "    #img_array = img_array.reshape(\n",
    "    #    (n_clips, total_num_frm, img_array.shape[-3], img_array.shape[-2], img_array.shape[-1]))\n",
    "    \n",
    "    # Convert numpy arrays to PIL Image objects\n",
    "    #clip_imgs = [Image.fromarray(img_array[0, j]) for j in range(total_num_frm)]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "77ae3ff4-eea4-43a3-93ea-3fe64ae00235",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [03:49<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "for video_name in tqdm(ls_videos):\n",
    "    video_path = os.path.join(videos_folder , video_name)\n",
    "    save_video_path = os.path.join('tmp/HACER_mid_frame/', video_name.split(\".\")[0] + '.png')\n",
    "    \n",
    "    img = extract_frames_video(video_path)\n",
    "    img.save(save_video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a8525-e79b-484e-8a70-a7926544051f",
   "metadata": {},
   "source": [
    "# GPT Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "916d4bfb-8055-4b96-9e94-24ec71b14f27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant(id='asst_ABDa32K49UsuaTEkag20jERw', created_at=1709576540, description=None, file_ids=[], instructions=\"Your role is to analyze images captured by surveillance cameras to determine the activity being performed and the emotion displayed by any person in the image. You're equipped to recognize 9 activity classes: drink, put on glasses, put on jacket, read, sit down, stand up, take off glasses, take off jacket, and write, as well as 5 emotion classes: happy, neutral, sad, angry, and disgust. When an image is input, accurately output the activity and emotion class in the format (activity - emotion). If no person is visible in the image, respond with 'unidentifiable' for both activity and emotion. Similarly, if the person's face is not clear, especially in surveillance footage, output 'unidentifiable' for the emotion while still attempting to identify the activity. Provide classifications in a straightforward manner, without additional commentary or tone, just the class names.\", metadata={}, model='gpt-4', name='Emotion and Activity Classifier', object='assistant', tools=[])\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=\"\")\n",
    "\n",
    "\n",
    "my_assistant = client.beta.assistants.retrieve(\"\")\n",
    "print(my_assistant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade05ad-d9d4-4016-8de6-f9d184444207",
   "metadata": {},
   "source": [
    "## Image encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2137b11-16c3-4184-b1ff-037854a2c209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"tmp/sitdown_angry_12_h.png\"\n",
    "\n",
    "# Getting the base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "with open(\"sitdown_angry_12_h.txt\", \"w\") as file:\n",
    "    file.write(base64_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae28c4b7-6ca9-4d54-b20d-21bf5afd3aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size is 0.7843818664550781 MB\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# Get the size of the file in bytes\n",
    "file_size_bytes = os.path.getsize(\"sitdown_angry_12_h.txt\")\n",
    "\n",
    "# Convert the size to megabytes\n",
    "file_size_mb = file_size_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"The size is {file_size_mb} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81275531-8092-4250-b3f2-f8018c211a3e",
   "metadata": {},
   "source": [
    "## Upload file to OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7ad08f-b4ba-47e8-952a-ea6a7775576b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "assistant_id = ''\n",
    "api_key = ''\n",
    "file_path = 'all_questions.json'\n",
    "\n",
    "def upload_file_to_existing_assistant(api_key, assistant_id, file_path):\n",
    "\n",
    "    # Initialize OpenAI client with the API key\n",
    "    client = OpenAI(api_key=api_key)\n",
    "\n",
    "    # Upload a file to OpenAI\n",
    "    with open(file_path, 'rb') as file:\n",
    "    uploaded_file = client.files.create(file=file, purpose='assistants')\n",
    "\n",
    "    # Add the uploaded file to the assistant\n",
    "    client.beta.assistants.files.create(assistant_id=assistant_id, file_id=uploaded_file.id)\n",
    "\n",
    "    print(f\"File '{file_path}' uploaded and added to the assistant with ID: {assistant_id}\")\n",
    "\n",
    "# Example usage\n",
    "upload_file_to_existing_assistant(api_key, assistant_id, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95dcfd-9db1-42dd-84e6-f1817a2e8d96",
   "metadata": {},
   "source": [
    "## Create a file listing all file names in the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "15744721-eaae-4099-937f-f2109fdd2bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# File path\n",
    "file_path = 'tmp/list_file.txt'\n",
    "\n",
    "# Save list to file\n",
    "with open(file_path, 'w') as file:\n",
    "    for item in image_name_ls:\n",
    "        file.write('%s\\n' % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67c747-ebe0-4778-ab4f-a2a18d47f332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_to_list(file_path):\n",
    "    # File path\n",
    "    file_path = 'tmp/list_file.txt'\n",
    "\n",
    "    # Read list from file\n",
    "    list_ = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            list_.append(line.strip())\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b391256-81a2-4aa0-bc9a-fd8983ebfd6b",
   "metadata": {},
   "source": [
    "## GPT4 Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e701e57e-fd59-4a26-a19c-98da377de554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import requests\n",
    "from openai import OpenAI\n",
    "\n",
    "def gpt4_vision(image_path, text, system_prompt):\n",
    "    # OpenAI API Key\n",
    "    api_key = ''\n",
    "\n",
    "    # Function to encode the image\n",
    "    def encode_image(image_path):\n",
    "        with open(image_path, \"rb\") as image_file:\n",
    "            return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "    # Path to your image\n",
    "    #image_path = \"tmp/HACER_mid_frame/putonglasses_neutral_3_t.png\"\n",
    "\n",
    "    # Getting the base64 string\n",
    "    base64_image = encode_image(image_path)\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4-vision-preview\",\n",
    "        \"messages\": [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": system_prompt\n",
    "            }\n",
    "          ]\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "            {\n",
    "                \"type\": \"text\",\n",
    "                \"text\": text\n",
    "            },\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{base64_image}\",\n",
    "                    \"detail\": \"low\"\n",
    "                }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "\n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "    output = response_json['choices'][0]['message']['content']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8db0a8d3-9322-4911-bb1d-487b36f4fecf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'chatcmpl-92FObifigkO64CJw7e0s2UX1yrmpH', 'object': 'chat.completion', 'created': 1710322865, 'model': 'gpt-4-1106-vision-preview', 'usage': {'prompt_tokens': 208, 'completion_tokens': 106, 'total_tokens': 314}, 'choices': [{'message': {'role': 'assistant', 'content': \"The person in the image is sitting on a chair with one hand resting on the chair's arm and the other holding what appears to be a mobile phone or a small object. Nearby is a small table with a water bottle on it, and a hookah is positioned to the right of the table. The person's expression seems neutral with a slightly closed mouth, not clearly indicating a strong emotion. It's difficult to ascertain the person's mood definitively without more context, but they appear to be at rest or waiting for something.\"}, 'finish_reason': 'stop', 'index': 0}]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"The person in the image is sitting on a chair with one hand resting on the chair's arm and the other holding what appears to be a mobile phone or a small object. Nearby is a small table with a water bottle on it, and a hookah is positioned to the right of the table. The person's expression seems neutral with a slightly closed mouth, not clearly indicating a strong emotion. It's difficult to ascertain the person's mood definitively without more context, but they appear to be at rest or waiting for something.\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What is the person doing and what is the current mood of the person?\"\n",
    "system_prompt = \"You are a virtual assistant powered by GPT-4 Vision. Your task is to analyze images and provide information based on the visual content. You can recognize objects, scenes, activities, and emotions in images. When given an image, you should describe what you see in clear and concise language. If asked, you can also provide insights or suggestions based on the image content. Your responses should be helpful and informative, assisting the user in understanding or making decisions based on the visual information.\"\n",
    "output = gpt4_vision('tmp/HACER_mid_frame/drink_angry_5_j.png', text, system_prompt)\n",
    "output "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfe329f-ae0b-48c7-a6de-978bd5293b31",
   "metadata": {},
   "source": [
    "## Implement GPT4-Vision with HACER dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d5e2c5cc-7882-49bb-939f-1a0449e248e9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 479\n",
      "1 / 479\n",
      "2 / 479\n",
      "3 / 479\n",
      "4 / 479\n",
      "5 / 479\n",
      "6 / 479\n",
      "7 / 479\n",
      "8 / 479\n",
      "9 / 479\n",
      "10 / 479\n",
      "11 / 479\n",
      "12 / 479\n",
      "13 / 479\n",
      "14 / 479\n",
      "15 / 479\n",
      "16 / 479\n",
      "17 / 479\n",
      "18 / 479\n",
      "19 / 479\n",
      "20 / 479\n",
      "21 / 479\n",
      "22 / 479\n",
      "23 / 479\n",
      "24 / 479\n",
      "25 / 479\n",
      "26 / 479\n",
      "27 / 479\n",
      "28 / 479\n",
      "29 / 479\n",
      "30 / 479\n",
      "31 / 479\n",
      "32 / 479\n",
      "33 / 479\n",
      "34 / 479\n",
      "35 / 479\n",
      "36 / 479\n",
      "37 / 479\n",
      "38 / 479\n",
      "39 / 479\n",
      "40 / 479\n",
      "41 / 479\n",
      "42 / 479\n",
      "43 / 479\n",
      "44 / 479\n",
      "45 / 479\n",
      "46 / 479\n",
      "47 / 479\n",
      "48 / 479\n",
      "49 / 479\n",
      "50 / 479\n",
      "51 / 479\n",
      "52 / 479\n",
      "53 / 479\n",
      "54 / 479\n",
      "55 / 479\n",
      "56 / 479\n",
      "57 / 479\n",
      "58 / 479\n",
      "59 / 479\n",
      "60 / 479\n",
      "61 / 479\n",
      "62 / 479\n",
      "63 / 479\n",
      "64 / 479\n",
      "65 / 479\n",
      "66 / 479\n",
      "67 / 479\n",
      "68 / 479\n",
      "69 / 479\n",
      "70 / 479\n",
      "71 / 479\n",
      "72 / 479\n",
      "73 / 479\n",
      "74 / 479\n",
      "75 / 479\n",
      "76 / 479\n",
      "77 / 479\n",
      "78 / 479\n",
      "79 / 479\n",
      "80 / 479\n",
      "81 / 479\n",
      "82 / 479\n",
      "83 / 479\n",
      "84 / 479\n",
      "85 / 479\n",
      "86 / 479\n",
      "87 / 479\n",
      "88 / 479\n",
      "89 / 479\n",
      "90 / 479\n",
      "91 / 479\n",
      "92 / 479\n",
      "93 / 479\n",
      "94 / 479\n",
      "95 / 479\n",
      "96 / 479\n",
      "97 / 479\n",
      "98 / 479\n",
      "99 / 479\n",
      "100 / 479\n",
      "101 / 479\n",
      "102 / 479\n",
      "103 / 479\n",
      "104 / 479\n",
      "105 / 479\n",
      "106 / 479\n",
      "107 / 479\n",
      "108 / 479\n",
      "109 / 479\n",
      "110 / 479\n",
      "111 / 479\n",
      "112 / 479\n",
      "113 / 479\n",
      "114 / 479\n",
      "115 / 479\n",
      "116 / 479\n",
      "117 / 479\n",
      "118 / 479\n",
      "119 / 479\n",
      "120 / 479\n",
      "121 / 479\n",
      "122 / 479\n",
      "123 / 479\n",
      "124 / 479\n",
      "125 / 479\n",
      "126 / 479\n",
      "127 / 479\n",
      "128 / 479\n",
      "129 / 479\n",
      "130 / 479\n",
      "131 / 479\n",
      "132 / 479\n",
      "133 / 479\n",
      "134 / 479\n",
      "135 / 479\n",
      "136 / 479\n",
      "137 / 479\n",
      "138 / 479\n",
      "139 / 479\n",
      "140 / 479\n",
      "141 / 479\n",
      "142 / 479\n",
      "143 / 479\n",
      "144 / 479\n",
      "145 / 479\n",
      "146 / 479\n",
      "147 / 479\n",
      "148 / 479\n",
      "149 / 479\n",
      "150 / 479\n",
      "151 / 479\n",
      "152 / 479\n",
      "153 / 479\n",
      "154 / 479\n",
      "155 / 479\n",
      "156 / 479\n",
      "157 / 479\n",
      "158 / 479\n",
      "159 / 479\n",
      "160 / 479\n",
      "161 / 479\n",
      "162 / 479\n",
      "163 / 479\n",
      "164 / 479\n",
      "165 / 479\n",
      "166 / 479\n",
      "167 / 479\n",
      "168 / 479\n",
      "169 / 479\n",
      "170 / 479\n",
      "171 / 479\n",
      "172 / 479\n",
      "173 / 479\n",
      "174 / 479\n",
      "175 / 479\n",
      "176 / 479\n",
      "177 / 479\n",
      "178 / 479\n",
      "179 / 479\n",
      "180 / 479\n",
      "181 / 479\n",
      "182 / 479\n",
      "183 / 479\n",
      "184 / 479\n",
      "185 / 479\n",
      "186 / 479\n",
      "187 / 479\n",
      "188 / 479\n",
      "189 / 479\n",
      "190 / 479\n",
      "191 / 479\n",
      "192 / 479\n",
      "193 / 479\n",
      "194 / 479\n",
      "195 / 479\n",
      "196 / 479\n",
      "197 / 479\n",
      "198 / 479\n",
      "199 / 479\n",
      "200 / 479\n",
      "201 / 479\n",
      "202 / 479\n",
      "203 / 479\n",
      "204 / 479\n",
      "205 / 479\n",
      "206 / 479\n",
      "207 / 479\n",
      "208 / 479\n",
      "209 / 479\n",
      "210 / 479\n",
      "211 / 479\n",
      "212 / 479\n",
      "213 / 479\n",
      "214 / 479\n",
      "215 / 479\n",
      "216 / 479\n",
      "217 / 479\n",
      "218 / 479\n",
      "219 / 479\n",
      "220 / 479\n",
      "221 / 479\n",
      "222 / 479\n",
      "223 / 479\n",
      "224 / 479\n",
      "225 / 479\n",
      "226 / 479\n",
      "227 / 479\n",
      "228 / 479\n",
      "229 / 479\n",
      "230 / 479\n",
      "231 / 479\n",
      "232 / 479\n",
      "233 / 479\n",
      "234 / 479\n",
      "235 / 479\n",
      "236 / 479\n",
      "237 / 479\n",
      "238 / 479\n",
      "239 / 479\n",
      "240 / 479\n",
      "241 / 479\n",
      "242 / 479\n",
      "243 / 479\n",
      "244 / 479\n",
      "245 / 479\n",
      "246 / 479\n",
      "247 / 479\n",
      "248 / 479\n",
      "249 / 479\n",
      "250 / 479\n",
      "251 / 479\n",
      "252 / 479\n",
      "253 / 479\n",
      "254 / 479\n",
      "255 / 479\n",
      "256 / 479\n",
      "257 / 479\n",
      "258 / 479\n",
      "259 / 479\n",
      "260 / 479\n",
      "261 / 479\n",
      "262 / 479\n",
      "263 / 479\n",
      "264 / 479\n",
      "265 / 479\n",
      "266 / 479\n",
      "267 / 479\n",
      "268 / 479\n",
      "269 / 479\n",
      "270 / 479\n",
      "271 / 479\n",
      "272 / 479\n",
      "273 / 479\n",
      "274 / 479\n",
      "275 / 479\n",
      "276 / 479\n",
      "277 / 479\n",
      "278 / 479\n",
      "279 / 479\n",
      "280 / 479\n",
      "281 / 479\n",
      "282 / 479\n",
      "283 / 479\n",
      "284 / 479\n",
      "285 / 479\n",
      "286 / 479\n",
      "287 / 479\n",
      "288 / 479\n",
      "289 / 479\n",
      "290 / 479\n",
      "291 / 479\n",
      "292 / 479\n",
      "293 / 479\n",
      "294 / 479\n",
      "295 / 479\n",
      "296 / 479\n",
      "297 / 479\n",
      "298 / 479\n",
      "299 / 479\n",
      "300 / 479\n",
      "301 / 479\n",
      "302 / 479\n",
      "303 / 479\n",
      "304 / 479\n",
      "305 / 479\n",
      "306 / 479\n",
      "307 / 479\n",
      "308 / 479\n",
      "309 / 479\n",
      "310 / 479\n",
      "311 / 479\n",
      "312 / 479\n",
      "313 / 479\n",
      "314 / 479\n",
      "315 / 479\n",
      "316 / 479\n",
      "317 / 479\n",
      "318 / 479\n",
      "319 / 479\n",
      "320 / 479\n",
      "321 / 479\n",
      "322 / 479\n",
      "323 / 479\n",
      "324 / 479\n",
      "325 / 479\n",
      "326 / 479\n",
      "327 / 479\n",
      "328 / 479\n",
      "329 / 479\n",
      "330 / 479\n",
      "331 / 479\n",
      "332 / 479\n",
      "333 / 479\n",
      "334 / 479\n",
      "335 / 479\n",
      "336 / 479\n",
      "337 / 479\n",
      "338 / 479\n",
      "339 / 479\n",
      "340 / 479\n",
      "341 / 479\n",
      "342 / 479\n",
      "343 / 479\n",
      "344 / 479\n",
      "345 / 479\n",
      "346 / 479\n",
      "347 / 479\n",
      "348 / 479\n",
      "349 / 479\n",
      "350 / 479\n",
      "351 / 479\n",
      "352 / 479\n",
      "353 / 479\n",
      "354 / 479\n",
      "355 / 479\n",
      "356 / 479\n",
      "357 / 479\n",
      "358 / 479\n",
      "359 / 479\n",
      "360 / 479\n",
      "361 / 479\n",
      "362 / 479\n",
      "363 / 479\n",
      "364 / 479\n",
      "365 / 479\n",
      "366 / 479\n",
      "367 / 479\n",
      "368 / 479\n",
      "369 / 479\n",
      "370 / 479\n",
      "371 / 479\n",
      "372 / 479\n",
      "373 / 479\n",
      "374 / 479\n",
      "375 / 479\n",
      "376 / 479\n",
      "377 / 479\n",
      "378 / 479\n",
      "379 / 479\n",
      "380 / 479\n",
      "381 / 479\n",
      "382 / 479\n",
      "383 / 479\n",
      "384 / 479\n",
      "385 / 479\n",
      "386 / 479\n",
      "387 / 479\n",
      "388 / 479\n",
      "389 / 479\n",
      "390 / 479\n",
      "391 / 479\n",
      "392 / 479\n",
      "393 / 479\n",
      "394 / 479\n",
      "395 / 479\n",
      "396 / 479\n",
      "397 / 479\n",
      "398 / 479\n",
      "399 / 479\n",
      "400 / 479\n",
      "401 / 479\n",
      "402 / 479\n",
      "403 / 479\n",
      "404 / 479\n",
      "405 / 479\n",
      "406 / 479\n",
      "407 / 479\n",
      "408 / 479\n",
      "409 / 479\n",
      "410 / 479\n",
      "411 / 479\n",
      "412 / 479\n",
      "413 / 479\n",
      "414 / 479\n",
      "415 / 479\n",
      "416 / 479\n",
      "417 / 479\n",
      "418 / 479\n",
      "419 / 479\n",
      "420 / 479\n",
      "421 / 479\n",
      "422 / 479\n",
      "423 / 479\n",
      "424 / 479\n",
      "425 / 479\n",
      "426 / 479\n",
      "427 / 479\n",
      "428 / 479\n",
      "429 / 479\n",
      "430 / 479\n",
      "431 / 479\n",
      "432 / 479\n",
      "433 / 479\n",
      "434 / 479\n",
      "435 / 479\n",
      "436 / 479\n",
      "437 / 479\n",
      "438 / 479\n",
      "439 / 479\n",
      "440 / 479\n",
      "441 / 479\n",
      "442 / 479\n",
      "443 / 479\n",
      "444 / 479\n",
      "445 / 479\n",
      "446 / 479\n",
      "447 / 479\n",
      "448 / 479\n",
      "449 / 479\n",
      "450 / 479\n",
      "451 / 479\n",
      "452 / 479\n",
      "453 / 479\n",
      "454 / 479\n",
      "455 / 479\n",
      "456 / 479\n",
      "457 / 479\n",
      "458 / 479\n",
      "459 / 479\n",
      "460 / 479\n",
      "461 / 479\n",
      "462 / 479\n",
      "463 / 479\n",
      "464 / 479\n",
      "465 / 479\n",
      "466 / 479\n",
      "467 / 479\n",
      "468 / 479\n",
      "469 / 479\n",
      "470 / 479\n",
      "471 / 479\n",
      "472 / 479\n",
      "473 / 479\n",
      "474 / 479\n",
      "475 / 479\n",
      "476 / 479\n",
      "477 / 479\n",
      "478 / 479\n",
      "['drink - neutral', 'drink - neutral', 'sit down - neutral', 'sit down - neutral', 'read - neutral', 'sit down - neutral', 'stand up - neutral', '(sit down - neutral)', '(drink - neutral)', 'drink - neutral', 'put on glasses - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'read - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - happy', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'read - neutral', 'drink - happy', 'drink - neutral', 'drink - happy', 'Activity - sit down\\nEmotion - happy', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'read - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', '(sit down - happy)', 'drink - happy', 'sit down - neutral', 'drink - happy', 'drink - neutral', 'sit down - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'sit down - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'sit down - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'unidentifiable - unidentifiable', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'Activity: Sit down\\nEmotion: Neutral', 'put on glasses - neutral', 'drink - neutral', 'take off glasses - neutral', '(put on glasses - neutral)', 'sit down - neutral', 'drink - neutral', 'put on glasses - neutral', 'put on glasses - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'Activity - sit down\\nEmotion - neutral', 'put on glasses - neutral', 'sit down - neutral', 'put on glasses - happy', 'take off glasses - neutral', 'put on glasses - neutral', '(sit down - happy)', '(put on glasses - neutral)', 'put on glasses - happy', 'drink - neutral', 'put on glasses - neutral', 'put on jacket - happy', 'drink - neutral', 'drink - neutral', 'take off glasses - neutral', 'put on glasses - neutral', '(put on glasses - neutral)', 'sit down - neutral', 'put on glasses - neutral', 'sit down - neutral', 'drink - neutral', 'drink - neutral', 'put on glasses - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'take off glasses - neutral', 'Activity: sit down - Emotion: neutral', '(put on glasses - neutral)', 'drink - neutral', 'sit down - neutral', '(put on jacket - neutral)', 'put on glasses - neutral', '(sit down - neutral)', 'drink - neutral', 'put on glasses - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'drink - neutral', 'put on glasses - neutral', 'Activity: Sit down\\nEmotion: Neutral', 'drink - neutral', 'drink - unidentifiable', 'drink - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - happy', 'put on jacket - neutral', 'put on jacket - neutral', 'put on glasses - happy', 'put on jacket - happy', 'put on jacket - happy', 'put on jacket - happy', 'put on jacket - happy', 'stand up - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'Activity: Put on jacket\\nEmotion: Neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'stand up - neutral', 'put on jacket - neutral', 'put on jacket - happy', 'put on jacket - neutral', '(put on jacket - neutral)', 'put on jacket - neutral', 'read - neutral', 'write - neutral', 'read - neutral', 'read - neutral', 'read - neutral', '(read - neutral)', 'read - neutral', '(read - neutral)', 'read - neutral', 'read - happy', 'read - happy', 'read - happy', 'read - happy', 'read - neutral', '(read - happy)', 'read - neutral', 'read - happy', 'read - neutral', '(read - neutral)', '(read - neutral)', '(read - neutral)', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', '(read - neutral)', 'read - neutral', '(read - neutral)', '(read - happy)', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'sit down - neutral', 'sit down - neutral', 'stand up - neutral', 'Activity: Stand up\\nEmotion: Neutral', 'sit down - neutral', 'stand up - happy', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', '(stand up - neutral)', '(stand up - neutral)', 'stand up - neutral', '(stand up - happy)', '(sit down - happy)', 'stand up - neutral', 'stand up - neutral', 'Activity: stand up\\nEmotion: neutral', 'sit down - neutral', 'sit down - happy', 'sit down - neutral', 'sit down - neutral', 'Activity: sit down - Emotion: unidentifiable', 'sit down - sad', 'sit down - neutral', 'sit down - happy', 'sit down - happy', '(sit down - happy)', 'sit down - happy', 'stand up - happy', 'sit down - neutral', 'stand up - happy', 'stand up - happy', 'sit down - neutral', 'Activity: Sit down - Emotion: Neutral', 'sit down - neutral', 'stand up - neutral', '(sit down - neutral)', 'sit down - neutral', 'sit down - neutral', 'Activity: sit down - Emotion: neutral', 'stand up - neutral', 'sit down - neutral', 'Activity - sit down\\nEmotion - unidentifiable', 'sit down - neutral', 'stand up - neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', '(sit down - neutral)', 'sit down - neutral', 'sit down - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'sit down - neutral', '(stand up - neutral)', 'Activity: Sit down\\nEmotion: Neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', 'Activity - Sit down\\nEmotion - Neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', '(sit down - neutral)', 'stand up - neutral', 'stand up - neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', 'Activity: stand up - Emotion: neutral', 'sit down - neutral', 'stand up - neutral', 'sit down - neutral', 'stand up - neutral', 'stand up - happy', 'sit down - neutral', 'stand up - happy', 'sit down - neutral', 'stand up - neutral', 'sit down - happy', 'stand up - happy', 'stand up - neutral', 'sit down - neutral', 'stand up - happy', 'stand up - neutral', 'stand up - happy', 'sit down - neutral', 'sit down - happy', 'stand up - happy', '(stand up - happy)', 'stand up - happy', 'stand up - happy', 'sit down - happy', '(stand up - happy)', 'unidentifiable - unidentifiable', 'stand up - happy', 'stand up - neutral', 'stand up - neutral', 'Activity: stand up\\nEmotion: neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'sit down - neutral', 'stand up - neutral', 'sit down - neutral', 'sit down - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'sit down - neutral', 'stand up - neutral', 'stand up - neutral', 'sit down - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', '(sit down - neutral)', 'sit down - neutral', 'sit down - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'stand up - neutral', 'Activity: Stand up - Emotion: Neutral', 'sit down - neutral', 'Activity: stand up - Emotion: neutral', 'sit down - neutral', 'stand up - neutral', 'sit down - neutral', 'stand up - neutral', 'Activity: sit down - Emotion: neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', '(sit down - neutral)', 'sit down - neutral', '(sit down - neutral)', 'sit down - neutral', 'sit down - neutral', 'put on glasses - neutral', 'sit down - neutral', '(put on glasses - neutral)', 'drink - neutral', 'Activity: Sit down - Emotion: Neutral', 'drink - happy', 'put on glasses - happy', 'sit down - happy', 'drink - neutral', 'take off glasses - neutral', 'drink - happy', 'put on jacket - neutral', 'sit down - happy', 'put on glasses - neutral', 'put on glasses - happy', '(sit down - happy)', 'sit down - neutral', 'sit down - sad', 'Activity: Sit down\\nEmotion: Neutral', 'drink - neutral', 'put on glasses - neutral', 'put on glasses - neutral', 'sit down - neutral', 'take off glasses - neutral', 'sit down - neutral', 'put on glasses - neutral', 'drink - neutral', 'sit down - neutral', 'put on glasses - neutral', 'drink - neutral', 'put on glasses - neutral', 'drink - neutral', 'drink - happy', 'Activity: sit down - Emotion: neutral', 'drink - neutral', 'Activity - sit down\\nEmotion - neutral', 'Activity: sit down - Emotion: neutral', 'take off glasses - neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', 'sit down - neutral', 'drink - happy', 'put on glasses - happy', 'put on glasses - neutral', 'sit down - neutral', 'drink - neutral', 'drink - neutral', '(sit down - neutral)', 'sit down - neutral', 'stand up - neutral', 'take off jacket - neutral', 'take off jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'Activity: Put on jacket - Emotion: Neutral', '(stand up - neutral)', '(put on jacket - neutral)', 'put on jacket - neutral', '(put on jacket - neutral)', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - happy', 'put on jacket - happy', '(put on jacket - happy)', '(put on jacket - happy)', '(stand up - neutral)', 'put on jacket - neutral', 'put on jacket - neutral', '(put on jacket - neutral)', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', '(put on jacket - neutral)', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'put on jacket - neutral', 'stand up - neutral', 'put on jacket - neutral', '(put on jacket - neutral)', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'sit down - neutral', 'read - neutral', 'write - neutral', 'read - neutral', 'read - neutral', 'read - happy', '(read - neutral)', 'read - neutral', 'read - happy', 'read - neutral', 'read - neutral', 'read - happy', 'read - neutral', 'read - happy', 'write - happy', 'read - neutral', 'read - neutral', 'write - neutral', 'write - neutral', 'sit down - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'read - neutral', 'write - neutral', 'read - neutral']\n",
      "['drink_angry_10_h', 'drink_angry_1_a', 'drink_angry_2_w', 'drink_angry_3_j', 'drink_angry_4_a', 'drink_angry_5_j', 'drink_angry_6_h', 'drink_angry_7_w', 'drink_angry_8_h', 'drink_angry_9_k', 'drink_disgust_10_m', 'drink_disgust_11_w', 'drink_disgust_12_h', 'drink_disgust_13_k', 'drink_disgust_14_t', 'drink_disgust_15_s', 'drink_disgust_16_t', 'drink_disgust_17_h', 'drink_disgust_18_k', 'drink_disgust_1_a', 'drink_disgust_2_w', 'drink_disgust_3_l', 'drink_disgust_4_j', 'drink_disgust_5_s', 'drink_disgust_6_m', 'drink_disgust_7_a', 'drink_disgust_8_j', 'drink_disgust_9_l', 'drink_happy_10_j', 'drink_happy_11_l', 'drink_happy_12_m', 'drink_happy_13_w', 'drink_happy_14_w', 'drink_happy_15_h', 'drink_happy_16_k', 'drink_happy_17_k', 'drink_happy_18_t', 'drink_happy_19_s', 'drink_happy_1_a', 'drink_happy_20_t', 'drink_happy_21_h', 'drink_happy_2_w', 'drink_happy_3_l', 'drink_happy_4_j', 'drink_happy_5_s', 'drink_happy_6_m', 'drink_happy_7_m', 'drink_happy_8_a', 'drink_happy_9_j', 'drink_neutral_10_m', 'drink_neutral_11_m', 'drink_neutral_12_w', 'drink_neutral_13_h', 'drink_neutral_14_t', 'drink_neutral_15_s', 'drink_neutral_16_t', 'drink_neutral_17_h', 'drink_neutral_1_a', 'drink_neutral_2_l', 'drink_neutral_3_j', 'drink_neutral_4_j', 'drink_neutral_5_s', 'drink_neutral_6_m', 'drink_neutral_7_a', 'drink_neutral_8_j', 'drink_neutral_9_l', 'drink_sad_10_s', 'drink_sad_1_w', 'drink_sad_2_l', 'drink_sad_3_s', 'drink_sad_4_m', 'drink_sad_5_l', 'drink_sad_6_m', 'drink_sad_7_w', 'drink_sad_8_w', 'drink_sad_9_k', 'putonglasses_angry_10_m', 'putonglasses_angry_11_h', 'putonglasses_angry_12_j', 'putonglasses_angry_1_s', 'putonglasses_angry_2_w', 'putonglasses_angry_3_h', 'putonglasses_angry_4_m', 'putonglasses_angry_5_w', 'putonglasses_angry_6_l', 'putonglasses_angry_7_j', 'putonglasses_angry_8_s', 'putonglasses_angry_9_l', 'putonglasses_happy_10_s', 'putonglasses_happy_11_a', 'putonglasses_happy_12_l', 'putonglasses_happy_13_m', 'putonglasses_happy_14_h', 'putonglasses_happy_15_j', 'putonglasses_happy_16_a', 'putonglasses_happy_1_s', 'putonglasses_happy_2_w', 'putonglasses_happy_3_t', 'putonglasses_happy_4_h', 'putonglasses_happy_5_m', 'putonglasses_happy_6_w', 'putonglasses_happy_7_l', 'putonglasses_happy_8_t', 'putonglasses_happy_9_j', 'putonglasses_neutral_10_m', 'putonglasses_neutral_11_m', 'putonglasses_neutral_12_h', 'putonglasses_neutral_13_j', 'putonglasses_neutral_14_a', 'putonglasses_neutral_1_s', 'putonglasses_neutral_2_w', 'putonglasses_neutral_3_t', 'putonglasses_neutral_4_h', 'putonglasses_neutral_5_w', 'putonglasses_neutral_6_t', 'putonglasses_neutral_7_j', 'putonglasses_neutral_8_s', 'putonglasses_neutral_9_l', 'putonglasses_sad_10_s', 'putonglasses_sad_11_a', 'putonglasses_sad_12_l', 'putonglasses_sad_13_m', 'putonglasses_sad_14_h', 'putonglasses_sad_15_j', 'putonglasses_sad_16_a', 'putonglasses_sad_1_s', 'putonglasses_sad_2_w', 'putonglasses_sad_3_t', 'putonglasses_sad_4_h', 'putonglasses_sad_5_m', 'putonglasses_sad_6_w', 'putonglasses_sad_7_l', 'putonglasses_sad_8_t', 'putonglasses_sad_9_j', 'putonjacket_angry_1_a', 'putonjacket_angry_2_m', 'putonjacket_angry_3_j', 'putonjacket_angry_4_a', 'putonjacket_angry_5_j', 'putonjacket_angry_6_k', 'putonjacket_angry_7_m', 'putonjacket_angry_8_k', 'putonjacket_happy_1_a', 'putonjacket_happy_2_m', 'putonjacket_happy_3_j', 'putonjacket_happy_4_a', 'putonjacket_happy_5_j', 'putonjacket_happy_6_k', 'putonjacket_happy_7_m', 'putonjacket_happy_8_k', 'putonjacket_neutral_10_a', 'putonjacket_neutral_1_a', 'putonjacket_neutral_2_m', 'putonjacket_neutral_3_j', 'putonjacket_neutral_4_a', 'putonjacket_neutral_5_a', 'putonjacket_neutral_6_j', 'putonjacket_neutral_7_k', 'putonjacket_neutral_8_m', 'putonjacket_neutral_9_k', 'putonjacket_sad_1_a', 'putonjacket_sad_2_m', 'putonjacket_sad_3_j', 'putonjacket_sad_4_j', 'putonjacket_sad_5_k', 'putonjacket_sad_6_m', 'read_angry_1_w', 'read_angry_2_j', 'read_angry_3_l', 'read_angry_4_w', 'read_angry_5_w', 'read_angry_6_l', 'read_angry_7_l', 'read_angry_8_h', 'read_angry_9_h', 'read_happy_10_j', 'read_happy_11_j', 'read_happy_1_w', 'read_happy_2_j', 'read_happy_3_l', 'read_happy_4_w', 'read_happy_5_w', 'read_happy_6_w', 'read_happy_7_l', 'read_happy_8_h', 'read_happy_9_h', 'read_neutral_10_h', 'read_neutral_11_a', 'read_neutral_12_t', 'read_neutral_13_k', 'read_neutral_14_a', 'read_neutral_15_a', 'read_neutral_16_k', 'read_neutral_17_t', 'read_neutral_1_w', 'read_neutral_2_l', 'read_neutral_3_l', 'read_neutral_4_w', 'read_neutral_5_w', 'read_neutral_6_l', 'read_neutral_7_l', 'read_neutral_8_h', 'read_neutral_9_h', 'read_sad_1_w', 'read_sad_2_w', 'read_sad_3_w', 'read_sad_4_h', 'read_sad_5_h', 'sitdown_angry_10_m', 'sitdown_angry_11_w', 'sitdown_angry_12_h', 'sitdown_angry_1_h', 'sitdown_angry_2_w', 'sitdown_angry_3_j', 'sitdown_angry_4_j', 'sitdown_angry_5_j', 'sitdown_angry_6_m', 'sitdown_angry_7_h', 'sitdown_angry_8_h', 'sitdown_angry_9_l', 'sitdown_happy_10_l', 'sitdown_happy_11_w', 'sitdown_happy_12_y', 'sitdown_happy_13_j', 'sitdown_happy_14_s', 'sitdown_happy_15_h', 'sitdown_happy_16_k', 'sitdown_happy_17_y', 'sitdown_happy_18_t', 'sitdown_happy_19_y', 'sitdown_happy_1_a', 'sitdown_happy_20_h', 'sitdown_happy_2_w', 'sitdown_happy_3_j', 'sitdown_happy_4_j', 'sitdown_happy_5_m', 'sitdown_happy_6_s', 'sitdown_happy_7_a', 'sitdown_happy_8_l', 'sitdown_happy_9_m', 'sitdown_neutral_10_l', 'sitdown_neutral_11_l', 'sitdown_neutral_12_w', 'sitdown_neutral_13_s', 'sitdown_neutral_14_h', 'sitdown_neutral_15_k', 'sitdown_neutral_16_y', 'sitdown_neutral_17_t', 'sitdown_neutral_18_t', 'sitdown_neutral_19_y', 'sitdown_neutral_1_a', 'sitdown_neutral_20_t', 'sitdown_neutral_21_t', 'sitdown_neutral_22_h', 'sitdown_neutral_2_a', 'sitdown_neutral_3_w', 'sitdown_neutral_4_j', 'sitdown_neutral_5_j', 'sitdown_neutral_6_s', 'sitdown_neutral_7_s', 'sitdown_neutral_8_h', 'sitdown_neutral_9_h', 'sitdown_sad_10_l', 'sitdown_sad_11_s', 'sitdown_sad_12_s', 'sitdown_sad_13_j', 'sitdown_sad_14_h', 'sitdown_sad_1_h', 'sitdown_sad_2_a', 'sitdown_sad_3_w', 'sitdown_sad_4_m', 'sitdown_sad_5_s', 'sitdown_sad_6_h', 'sitdown_sad_7_a', 'sitdown_sad_8_l', 'sitdown_sad_9_m', 'standup_angry_10_w', 'standup_angry_11_s', 'standup_angry_12_h', 'standup_angry_1_h', 'standup_angry_2_w', 'standup_angry_3_j', 'standup_angry_4_j', 'standup_angry_5_j', 'standup_angry_6_m', 'standup_angry_7_h', 'standup_angry_8_l', 'standup_angry_9_w', 'standup_happy_10_l', 'standup_happy_11_m', 'standup_happy_12_l', 'standup_happy_13_y', 'standup_happy_14_j', 'standup_happy_15_s', 'standup_happy_16_h', 'standup_happy_17_k', 'standup_happy_18_y', 'standup_happy_19_y', 'standup_happy_1_a', 'standup_happy_20_y', 'standup_happy_21_t', 'standup_happy_22_y', 'standup_happy_23_t', 'standup_happy_24_h', 'standup_happy_2_w', 'standup_happy_3_j', 'standup_happy_4_j', 'standup_happy_5_m', 'standup_happy_6_s', 'standup_happy_7_h', 'standup_happy_8_a', 'standup_happy_9_h', 'standup_neutral_10_l', 'standup_neutral_11_m', 'standup_neutral_12_l', 'standup_neutral_13_y', 'standup_neutral_14_s', 'standup_neutral_15_h', 'standup_neutral_16_k', 'standup_neutral_17_y', 'standup_neutral_18_t', 'standup_neutral_19_y', 'standup_neutral_1_a', 'standup_neutral_20_t', 'standup_neutral_2_w', 'standup_neutral_3_j', 'standup_neutral_4_j', 'standup_neutral_5_s', 'standup_neutral_6_s', 'standup_neutral_7_h', 'standup_neutral_8_a', 'standup_neutral_9_h', 'standup_sad_10_l', 'standup_sad_11_l', 'standup_sad_12_w', 'standup_sad_13_s', 'standup_sad_14_j', 'standup_sad_15_h', 'standup_sad_16_l', 'standup_sad_1_h', 'standup_sad_2_h', 'standup_sad_3_a', 'standup_sad_4_w', 'standup_sad_5_m', 'standup_sad_6_s', 'standup_sad_7_h', 'standup_sad_8_a', 'standup_sad_9_m', 'takeoffglasses_angry_10_m', 'takeoffglasses_angry_11_h', 'takeoffglasses_angry_12_j', 'takeoffglasses_angry_1_s', 'takeoffglasses_angry_2_w', 'takeoffglasses_angry_3_h', 'takeoffglasses_angry_4_m', 'takeoffglasses_angry_5_w', 'takeoffglasses_angry_6_l', 'takeoffglasses_angry_7_j', 'takeoffglasses_angry_8_s', 'takeoffglasses_angry_9_l', 'takeoffglasses_happy_10_s', 'takeoffglasses_happy_11_a', 'takeoffglasses_happy_12_l', 'takeoffglasses_happy_13_m', 'takeoffglasses_happy_14_h', 'takeoffglasses_happy_15_j', 'takeoffglasses_happy_1_s', 'takeoffglasses_happy_2_w', 'takeoffglasses_happy_3_t', 'takeoffglasses_happy_4_h', 'takeoffglasses_happy_5_m', 'takeoffglasses_happy_6_w', 'takeoffglasses_happy_7_l', 'takeoffglasses_happy_8_t', 'takeoffglasses_happy_9_j', 'takeoffglasses_neutral_10_a', 'takeoffglasses_neutral_11_l', 'takeoffglasses_neutral_12_m', 'takeoffglasses_neutral_13_m', 'takeoffglasses_neutral_14_h', 'takeoffglasses_neutral_15_j', 'takeoffglasses_neutral_16_a', 'takeoffglasses_neutral_17_a', 'takeoffglasses_neutral_1_s', 'takeoffglasses_neutral_2_w', 'takeoffglasses_neutral_3_t', 'takeoffglasses_neutral_4_h', 'takeoffglasses_neutral_5_w', 'takeoffglasses_neutral_6_l', 'takeoffglasses_neutral_7_t', 'takeoffglasses_neutral_8_J', 'takeoffglasses_neutral_9_s', 'takeoffglasses_sad_10_s', 'takeoffglasses_sad_11_a', 'takeoffglasses_sad_12_l', 'takeoffglasses_sad_13_m', 'takeoffglasses_sad_14_h', 'takeoffglasses_sad_15_j', 'takeoffglasses_sad_1_s', 'takeoffglasses_sad_2_w', 'takeoffglasses_sad_3_t', 'takeoffglasses_sad_4_h', 'takeoffglasses_sad_5_m', 'takeoffglasses_sad_6_w', 'takeoffglasses_sad_7_l', 'takeoffglasses_sad_8_t', 'takeoffglasses_sad_9_j', 'takeoffjacket_angry_1_a', 'takeoffjacket_angry_2_m', 'takeoffjacket_angry_3_k', 'takeoffjacket_angry_4_a', 'takeoffjacket_angry_5_j', 'takeoffjacket_angry_6_k', 'takeoffjacket_angry_7_k', 'takeoffjacket_angry_8_k', 'takeoffjacket_happy_10_a', 'takeoffjacket_happy_1_a', 'takeoffjacket_happy_2_m', 'takeoffjacket_happy_3_j', 'takeoffjacket_happy_4_a', 'takeoffjacket_happy_5_j', 'takeoffjacket_happy_6_k', 'takeoffjacket_happy_7_m', 'takeoffjacket_happy_8_a', 'takeoffjacket_happy_9_k', 'takeoffjacket_neutral_1_a', 'takeoffjacket_neutral_2_m', 'takeoffjacket_neutral_3_j', 'takeoffjacket_neutral_4_a', 'takeoffjacket_neutral_5_a', 'takeoffjacket_neutral_6_j', 'takeoffjacket_neutral_7_k', 'takeoffjacket_neutral_8_m', 'takeoffjacket_neutral_9_k', 'takeoffjacket_sad_1_a', 'takeoffjacket_sad_2_j', 'takeoffjacket_sad_3_j', 'takeoffjacket_sad_4_k', 'takeoffjacket_sad_5_m', 'takeoffjacket_sad_6_k', 'takeoffjacket_sad_7_k', 'write_angry_10_s', 'write_angry_11_l', 'write_angry_12_l', 'write_angry_13_l', 'write_angry_14_t', 'write_angry_1_w', 'write_angry_2_w', 'write_angry_3_j', 'write_angry_4_s', 'write_angry_5_s', 'write_angry_6_w', 'write_angry_7_w', 'write_angry_8_w', 'write_angry_9_s', 'write_happy_10_j', 'write_happy_11_t', 'write_happy_12_t', 'write_happy_1_w', 'write_happy_2_w', 'write_happy_3_j', 'write_happy_4_s', 'write_happy_5_w', 'write_happy_6_s', 'write_happy_7_l', 'write_happy_8_l', 'write_happy_9_l', 'write_neutral_10_t', 'write_neutral_11_a', 'write_neutral_12_a', 'write_neutral_1_w', 'write_neutral_2_j', 'write_neutral_3_s', 'write_neutral_4_s', 'write_neutral_5_s', 'write_neutral_6_l', 'write_neutral_7_j', 'write_neutral_8_a', 'write_neutral_9_t']\n"
     ]
    }
   ],
   "source": [
    "# File path\n",
    "file_path = 'tmp/list_file.txt'\n",
    "image_name_ls = read_txt_to_list(file_path)\n",
    "\n",
    "output_ls = []\n",
    "name_ls = []\n",
    "for i, image_name in enumerate(image_name_ls):\n",
    "    try:\n",
    "        print(f'{i} / 479')\n",
    "        image_path = f'tmp/HACER_mid_frame/{image_name}.png'\n",
    "        system_prompt = \"Your role is to analyze images captured by surveillance cameras to determine the activity being performed and the emotion displayed by any person in the image. You're equipped to recognize 9 activity classes: drink, put on glasses, put on jacket, read, sit down, stand up, take off glasses, take off jacket, and write, as well as 5 emotion classes: happy, neutral, sad, angry, and disgust. When an image is input, accurately output the activity and emotion class in the format (activity - emotion). If no person is visible in the image, respond with 'unidentifiable' for both activity and emotion. Similarly, if the person's face is not clear, especially in surveillance footage, output 'unidentifiable' for the emotion while still attempting to identify the activity. Provide classifications in a straightforward manner, without additional commentary or tone, just the class names.\"\n",
    "        text = \"Classify the activities and emotions in this image.\"\n",
    "        output = gpt4_vision(image_path, text, system_prompt)\n",
    "        output_ls.append(output)\n",
    "        name_ls.append(image_name)\n",
    "    except:\n",
    "        print(f'Image {i}th is not processed sucessfully!')\n",
    "    \n",
    "df = pd.DataFrame({'Video Name': name_ls, 'Output': output_ls})\n",
    "df.to_csv('smartcare_eval_output_gpt4.csv', index=False)\n",
    "print(output_ls)\n",
    "print(name_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6fd151-fa0a-4f4d-80e6-ffac02cdc553",
   "metadata": {},
   "source": [
    "# Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "867f687d-c8d3-4058-8eb9-cc9010c2cf56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_llava = pd.read_csv('smartcare_eval_output_llava_1.csv')\n",
    "df_vcgpt = pd.read_csv('smartcare_eval_output_videochatgpt_1_extracted.csv')\n",
    "df_gpt4 = pd.read_csv('smartcare_eval_output_gpt4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b26249f0-8967-4659-be99-8c1c56fe5a07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drink_angry_10_h</td>\n",
       "      <td>drink - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink_angry_1_a</td>\n",
       "      <td>drink - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drink_angry_2_w</td>\n",
       "      <td>sit down - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drink_angry_3_j</td>\n",
       "      <td>sit down - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drink_angry_4_a</td>\n",
       "      <td>read - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>write_neutral_5_s</td>\n",
       "      <td>read - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>write_neutral_6_l</td>\n",
       "      <td>read - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>write_neutral_7_j</td>\n",
       "      <td>read - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>write_neutral_8_a</td>\n",
       "      <td>write - neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>write_neutral_9_t</td>\n",
       "      <td>read - neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Video Name              Output\n",
       "0     drink_angry_10_h     drink - neutral\n",
       "1      drink_angry_1_a     drink - neutral\n",
       "2      drink_angry_2_w  sit down - neutral\n",
       "3      drink_angry_3_j  sit down - neutral\n",
       "4      drink_angry_4_a      read - neutral\n",
       "..                 ...                 ...\n",
       "474  write_neutral_5_s      read - neutral\n",
       "475  write_neutral_6_l      read - neutral\n",
       "476  write_neutral_7_j      read - neutral\n",
       "477  write_neutral_8_a     write - neutral\n",
       "478  write_neutral_9_t      read - neutral\n",
       "\n",
       "[479 rows x 2 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gpt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73174df4-7741-43ac-8f63-c42064ce4ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "c12cf830-83bc-42ca-b7a4-e5b6459168e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_pred_act_emo(df, model):\n",
    "    pred_dict = {}\n",
    "    for i in tqdm(range(len(df))):\n",
    "        if model == 'llava':\n",
    "            video_name = df.iloc[i]['Video Name']\n",
    "            output = df.iloc[i]['Output'].lower()\n",
    "            temp = output.split('\\n')\n",
    "            act = temp[0].replace('activity: ', '').split(', ')\n",
    "            emo = temp[1].replace('emotion: ', '').split(', ')\n",
    "            #print(act)\n",
    "            #print(emo)\n",
    "            #print(video_name)\n",
    "            #pred_dict[video_name] = {'act': act, 'emo': emo}\n",
    "            #print(pred_dict)\n",
    "            #break\n",
    "        if model == 'video_chatgpt':\n",
    "            video_name = df.iloc[i]['Video Name']\n",
    "            output = df.iloc[i]['Extracted_Output'].lower()\n",
    "            temp = output[2:].split('- ')\n",
    "            act = temp[0].replace('activity: ', '').split(', ')\n",
    "            emo = temp[1].replace('emotion: ', '').split(', ')\n",
    "        if model == 'gpt4':\n",
    "            try:\n",
    "                video_name = df.iloc[i]['Video Name']\n",
    "                output = df.iloc[i]['Output'].lower()\n",
    "                temp = output.replace('(','').replace(')','')\n",
    "                temp = temp.replace('\\nemotion:', ' -').replace('activity: ', '')\n",
    "                temp = temp.replace('\\nemotion', '').replace('activity - ', '')\n",
    "                temp = temp.split(' - ')\n",
    "                act = temp[0].split(', ')\n",
    "                emo = temp[1].split(', ')\n",
    "            except:\n",
    "                print(i)\n",
    "                print(temp)\n",
    "        pred_dict[video_name] = {'act': act, 'emo': emo, 'output': output}\n",
    "    return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e989e237-0cb0-4317-b482-e0fb57dfdbaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:00<00:00, 16976.25it/s]\n"
     ]
    }
   ],
   "source": [
    "gpt4_pred = extract_pred_act_emo(df_gpt4, model='gpt4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "95e9cfab-db43-4d5e-a058-51218966ac83",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:00<00:00, 16754.69it/s]\n"
     ]
    }
   ],
   "source": [
    "vcgpt_pred = extract_pred_act_emo(df_vcgpt, model='video_chatgpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "1beb2127-0401-4354-bd4a-3cba567f368e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 479/479 [00:00<00:00, 17792.62it/s]\n"
     ]
    }
   ],
   "source": [
    "llava_pred = extract_pred_act_emo(df_llava, model='llava')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "92945b20-e718-482a-9a1f-24e1690f128b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('standup', 'happy')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ground_truth_from_name(file_name):\n",
    "    temp = file_name.split('_')\n",
    "    act = temp[0]\n",
    "    emo = temp[1]\n",
    "    return act, emo\n",
    "\n",
    "ground_truth_from_name(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bbc4e9bd-3da9-4550-91c3-a18874c70f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "act_mapping = {\n",
    "    'drink': ['drink', 'drinking'], \n",
    "    'putonglasses': ['put on glasses', 'putting on glasses'], \n",
    "    'putonjacket': ['put on jacket', 'putting on jacket'], \n",
    "    'read': ['read', 'reading'], \n",
    "    'sitdown': ['sit', 'sitting'], \n",
    "    'standup': ['stand', 'standing'], \n",
    "    'takeoffglasses': ['take off glasses', 'taking off glasses'], \n",
    "    'takeoffjacket': ['take off jacket', 'taking off jacket'],\n",
    "    'write': ['write', 'writing']\n",
    "}\n",
    "\n",
    "emo_mapping = {\n",
    "    'angry': ['angry', 'anger', 'angered'],\n",
    "    'disgust': ['disgust', 'disgusted', 'disgusting'],\n",
    "    'happy': ['happy', 'happiness'],\n",
    "    'neutral': ['neutral', 'unemotional'],\n",
    "    'sad': ['sad', 'sadness']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "dd8461dd-47bf-4ef8-a95e-fca6e1a936dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mapping_pred_and_class(dict_):\n",
    "    act_pred_arr = []\n",
    "    emo_pred_arr = []\n",
    "    act_true_arr = []\n",
    "    emo_true_arr = []\n",
    "    act_nan_cnt = 0\n",
    "    emo_nan_cnt = 0\n",
    "    #file_name_arr = []\n",
    "    file_name_ls = dict_.keys()\n",
    "    \n",
    "    for file_name in file_name_ls:\n",
    "        #file_name_arr.append(file_name)\n",
    "        #print(file_name)\n",
    "        act_true, emo_true = ground_truth_from_name(file_name)\n",
    "        act_true_arr.append(act_true)\n",
    "        emo_true_arr.append(emo_true)\n",
    "        \n",
    "        # check the correctness of activity prediction\n",
    "        act_temp = 'unidentified'\n",
    "        for class_ in act_mapping.keys():\n",
    "            flag = 0\n",
    "            for act in dict_[file_name]['act']:\n",
    "                # check unidentified\n",
    "                if 'unidentified' in act:\n",
    "                    act_nan_cnt+=1\n",
    "                    break\n",
    "                if 'unidentifiable' in act:\n",
    "                    act_nan_cnt+=1\n",
    "                    break\n",
    "                \n",
    "                # check each cases in a class\n",
    "                for criteria in act_mapping[class_]:  \n",
    "                    if criteria in act:\n",
    "                        # if the ground truth appears, stop the loop, else continue to run\n",
    "                        if class_ == act_true:\n",
    "                            act_temp = act_true\n",
    "                            flag = 1\n",
    "                        else:\n",
    "                            act_temp = class_\n",
    "                    if flag==1: break\n",
    "                if flag==1: break   \n",
    "            if flag==1: break   \n",
    "        act_pred_arr.append(act_temp)\n",
    "                        \n",
    "                \n",
    "        # check the correctness of emotion prediction\n",
    "        emo_temp = 'unidentified'\n",
    "        for class_ in emo_mapping.keys():\n",
    "            flag = 0\n",
    "            for emo in dict_[file_name]['emo']:\n",
    "                # check unidentified\n",
    "                if 'unidentified' in emo:\n",
    "                    emo_nan_cnt+=1\n",
    "                    break\n",
    "                if 'unidentifiable' in emo:\n",
    "                    emo_nan_cnt+=1\n",
    "                    break\n",
    "                \n",
    "                # check each cases in a class\n",
    "                for criteria in emo_mapping[class_]:  \n",
    "                    if criteria in emo:\n",
    "                        # if the ground truth appears, stop the loop, else continue to run\n",
    "                        if class_ == emo_true:\n",
    "                            emo_temp = emo_true\n",
    "                            flag = 1\n",
    "                        else:\n",
    "                            emo_temp = class_\n",
    "                    if flag==1: break\n",
    "                if flag==1: break   \n",
    "            if flag==1: break   \n",
    "        emo_pred_arr.append(emo_temp)\n",
    "    return (act_pred_arr, act_true_arr, act_nan_cnt, emo_pred_arr, emo_true_arr, emo_nan_cnt)\n",
    "\n",
    "eval_vcgpt = mapping_pred_and_class(vcgpt_pred)\n",
    "eval_gpt4 = mapping_pred_and_class(gpt4_pred)\n",
    "eval_llava = mapping_pred_and_class(llava_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "342435d3-ec96-405a-bbc9-16dc1b7d7ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       angry       0.00      0.00      0.00        97\n",
      "     disgust       0.00      0.00      0.00        18\n",
      "       happy       0.88      0.45      0.59       137\n",
      "     neutral       0.33      0.98      0.50       138\n",
      "         sad       0.00      0.00      0.00        89\n",
      "unidentified       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.41       479\n",
      "   macro avg       0.20      0.24      0.18       479\n",
      "weighted avg       0.35      0.41      0.31       479\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your arrays\n",
    "predictions = eval_gpt4[3]\n",
    "groundtruth = eval_gpt4[4]\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(groundtruth, predictions)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='g', xticklabels=set(groundtruth + predictions), yticklabels=set(groundtruth + predictions))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(groundtruth, predictions)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "37212678-ed78-4cd7-8b9c-2398d553c646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1890\n",
      "1050\n",
      "9\n",
      "645\n",
      "18\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(eval_llava[2])\n",
    "print(eval_llava[5])\n",
    "print(eval_vcgpt[2])\n",
    "print(eval_vcgpt[5])\n",
    "print(eval_gpt4[2])\n",
    "print(eval_gpt4[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "baae937e-d91f-459c-8732-717b3bc91a77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'sad', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'sad', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'happy', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'sad', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'happy', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'happy', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'sad', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'happy', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'unidentified', 'unidentified', 'sad', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified', 'neutral', 'neutral', 'neutral', 'sad', 'neutral', 'unidentified', 'unidentified', 'neutral', 'unidentified', 'unidentified', 'neutral', 'neutral', 'neutral', 'unidentified']\n"
     ]
    }
   ],
   "source": [
    "print(eval_llava[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "be1edc7e-d1e3-42a8-83db-3db4353905d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "happy - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "neutral - disgust\n",
      "happy - disgust\n",
      "neutral - disgust\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "unidentified - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "unidentified - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "happy - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "happy - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "happy - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "unidentified - happy\n",
      "sad - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "unidentified - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "unidentified - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "sad - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "happy - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "happy - sad\n",
      "happy - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - sad\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - angry\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "happy - happy\n",
      "happy - happy\n",
      "neutral - happy\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n",
      "neutral - neutral\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(eval_gpt4[3])):\n",
    "    print(f'{eval_gpt4[3][i]} - {eval_gpt4[4][i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124cb9b1-2a17-49b8-a49a-b1080b9b2a9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
